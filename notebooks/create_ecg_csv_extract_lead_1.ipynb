{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20353c43",
   "metadata": {},
   "source": [
    "# Goal of this notebook: \n",
    "### Create a Dataframe that maps file_name, rhythm_label, EKG_lead_1_values.\n",
    "**I work with the Diagnostics.xlsx and ECGDataDenoised.zip files provided by the authors**\n",
    "\n",
    "**Process:**\n",
    "\n",
    "**1. Process the Diagnostic.xlsx file (this file maps ecg file name with labeled heart rhythm)**\n",
    "\n",
    "**2. Unzip ECGDataDenoised.zip and unload the 10646 .csv files with 12 lead ECG readings.** \n",
    "**(names of these files correlate to Diagnostic.xlsx in step 1)**\n",
    "\n",
    "**3. Extract Lead 1 data from 12 lead ECG reading csv and create ECG Dictionary/Dataframe.**\n",
    " - This created dictionary has file name mapped to rhythm label and the ecg microvolt readings (a list of floats stored as string)\n",
    " - Lead 1 is what an apple watch would use for an EKG\n",
    " \n",
    "**4. Save new ECG Dictionary/Dataframe as CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6132ae8",
   "metadata": {},
   "source": [
    "## About the EKG dataset \n",
    "### **Datasets**: **A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients**\n",
    "\n",
    "\"Description:\n",
    "This newly inaugurated research database for 12-lead electrocardiogram signals was created under the auspices of Chapman University and Shaoxing People's Hospital (Shaoxing Hospital Zhejiang University School of Medicine) and aims at enabling the scientific community in conducting new studies on arrhythmia and other cardiovascular conditions. Certain types of arrhythmias, such as atrial fibrillation, have a pronounced negative impact on public health, quality of life, and medical expenditures. As a non-invasive test, the long term ECG monitoring is a major and vital diagnostic tool for detecting these conditions. However, such a practice generates a considerable amount of data that analysis of which require considerable time and effort by human experts. Advancement of modern machine learning and statistical tools can be trained on high quality, large data to achieve high levels of automated diagnostic accuracy. Thus, we collected and disseminated this novel database that contains 12-lead ECGs of 10,646 patients with 500 Hz sampling rate that features 11 common rhythms and 67 additional cardiovascular conditions, all labeled by professional experts. For each subject, a sample size of 10 seconds (12-dimension 5000 samples) was available. The dataset can be used to design, compare, and fine tune new and classical statistical and machine learning techniques in studies focused on arrhythmia and other cardiovascular conditions.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239229b",
   "metadata": {},
   "source": [
    "\n",
    "**Dataset Citation:**\n",
    "\n",
    "Zheng, Jianwei; Rakovski, Cyril; Danioko, Sidy; Zhang, Jianming; Yao, Hai; Hangyuan, Guo (2019). A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. figshare. Collection. https://doi.org/10.6084/m9.figshare.c.4560497\n",
    "\n",
    "Zheng, Jianwei (2019). ECGDataDenoised.zip. figshare. Dataset. https://doi.org/10.6084/m9.figshare.8378291.v1\n",
    "\n",
    "Zheng, Jianwei (2019). Diagnostics.xlsx. figshare. Dataset. https://doi.org/10.6084/m9.figshare.8360408.v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48076a6d",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb48c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8406ef",
   "metadata": {},
   "source": [
    "### Create file paths to ECGDataDenoised.zip and Diagnostics.xlsx\n",
    "** Define a file path for each variable in the cell below!!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e888aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = r'downloads/ecg_source_downloads/ECGDataDenoised.zip'         # This is the file path to the raw values of EKG readings in microvolts that are taken 500 times a second\n",
    "diagnostic_file_path = r'downloads/ecg_source_downloads/Diagnostics.xlsx'     # This is the label that the creators of the dataset gave to each EKG. They associate a label to file name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86077de5",
   "metadata": {},
   "source": [
    "### 1. Process the Diagnostic.xlsx file\n",
    "**This file maps each of the 'FileName' to a heart 'Rhythm' labeled by an expert.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ffda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dataframe extracting the file name and the heart rhythm label for the file\n",
    "# As mentioned in comment above this will be a file name with a label for heart rhythm\n",
    "diagnostics_df = pd.read_excel(diagnostic_file_path, usecols=\"A,B\", header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5043c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Rhythm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180113_171327_27000</td>\n",
       "      <td>AFIB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180112_073319_29000</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180111_165520_97000</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_121940_44000</td>\n",
       "      <td>SB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180112_122850_57000</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FileName Rhythm\n",
       "0  MUSE_20180113_171327_27000   AFIB\n",
       "1  MUSE_20180112_073319_29000     SB\n",
       "2  MUSE_20180111_165520_97000     SA\n",
       "3  MUSE_20180113_121940_44000     SB\n",
       "4  MUSE_20180112_122850_57000     AF"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnostics_df.head() # View head of DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48222c62",
   "metadata": {},
   "source": [
    "### 2. Unzip ECGDataDenoised.zip\n",
    "**Unzipping will create over 10,000 .csv files each with an individual ECGs microvolts values (500 readings/second for 10 seconds on 12 leads)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ECG CSVs to: datasets/created_ecg_csv/ECGDataDenoised\n"
     ]
    }
   ],
   "source": [
    "# ----- Unzip ECGDataDenoised.zip -----\n",
    "# Create a directory to extract the CSVs into\n",
    "\n",
    "output_dir = r'datasets/created_ecg_csv/ECGDataDenoised'  # ---!! Define your own path to an output directory for the 10,000+ 12 lead EKG csv!!--\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)              # Create directory or verify it is there\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref: # extract all files from zip to output directory\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(f\"Extracted ECG CSVs to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93927cb5",
   "metadata": {},
   "source": [
    "### 3. Extract Lead 1 From 12 lead ECG values csv and create ECG Dictionary/Dataframe.\n",
    "\n",
    "#### **!!! --- The 12 leads are not labeled in the excel format. I am assuming the column A, is Lead 1 --- !!!**\n",
    "\n",
    "**This is an assumption and not verified with authors of paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf0ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping MUSE_20180113_124215_52000.csv: Expected 5000 values, but found 1926\n",
      "\n",
      "Created dataset with 10645 entries.\n",
      "Example of a processed entry:\n",
      "file_name                             MUSE_20180118_132508_86000\n",
      "rhythm                                                        SB\n",
      "lead_1_data    [28.56, 6.1529, -11.824, -22.725, -26.701, -25...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize an empty list to store our processed EKG data and labels\n",
    "ekg_dataset = []\n",
    "\n",
    "# Get a list of all CSV files in the extracted directory\n",
    "ecg_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]  # This will return a list of directory of the 12lead csv files extracted above\n",
    "\n",
    "# Iterate through each ECG CSV file\n",
    "for ecg_file in ecg_files:\n",
    "    file_name_without_ext = os.path.splitext(ecg_file)[0]\n",
    "\n",
    "    # Find the corresponding rhythm from the diagnostics DataFrame to map a rhythm\n",
    "    rhythm_entry = diagnostics_df[diagnostics_df['FileName'] == file_name_without_ext]\n",
    "\n",
    "    if not rhythm_entry.empty:\n",
    "        rhythm = rhythm_entry['Rhythm'].iloc[0] # This will associate a rhythm name to file \n",
    "\n",
    "        # Construct the full path to the CSV file\n",
    "        csv_path = os.path.join(output_dir, ecg_file)\n",
    "\n",
    "        try:\n",
    "            # Read only the first column of the CSV (assuming it's Lead 1)\n",
    "            # Since there are no headers, we'll read it without header and select the first column by index\n",
    "            ecg_data = pd.read_csv(csv_path, header=None, usecols=[0])\n",
    "\n",
    "            # Ensure 5000 values are present\n",
    "            if len(ecg_data) == 5000:\n",
    "                # Store the filename, rhythm, and Lead 1 data\n",
    "                ekg_dataset.append({\n",
    "                    'file_name': file_name_without_ext,\n",
    "                    'rhythm': rhythm,\n",
    "                    'lead_1_data': ecg_data[0].tolist() # Convert to list for easier handling\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Skipping {ecg_file}: Expected 5000 values, but found {len(ecg_data)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ecg_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"No rhythm found for {file_name_without_ext} in Diagnostics.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame (optional, but good for further analysis)\n",
    "final_ekg_df = pd.DataFrame(ekg_dataset)\n",
    "\n",
    "print(f\"\\nCreated dataset with {len(final_ekg_df)} entries.\")\n",
    "print(\"Example of a processed entry:\")\n",
    "if not final_ekg_df.empty:\n",
    "    print(final_ekg_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6f546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>rhythm</th>\n",
       "      <th>lead_1_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSE_20180118_132508_86000</td>\n",
       "      <td>SB</td>\n",
       "      <td>[28.56, 6.1529, -11.824, -22.725, -26.701, -25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSE_20180116_124640_27000</td>\n",
       "      <td>ST</td>\n",
       "      <td>[7.7133, 3.4957, -1.6378, -7.7151, -13.76, -18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MUSE_20180113_171837_63000</td>\n",
       "      <td>SB</td>\n",
       "      <td>[-10.816, -11.143, -11.407, -11.518, -11.336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUSE_20180113_134112_95000</td>\n",
       "      <td>AFIB</td>\n",
       "      <td>[-86.666, -82.155, -76.289, -68.804, -61.092, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSE_20180118_135058_59000</td>\n",
       "      <td>SA</td>\n",
       "      <td>[-68.682, -67.147, -64.614, -60.604, -55.135, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_name rhythm  \\\n",
       "0  MUSE_20180118_132508_86000     SB   \n",
       "1  MUSE_20180116_124640_27000     ST   \n",
       "2  MUSE_20180113_171837_63000     SB   \n",
       "3  MUSE_20180113_134112_95000   AFIB   \n",
       "4  MUSE_20180118_135058_59000     SA   \n",
       "\n",
       "                                         lead_1_data  \n",
       "0  [28.56, 6.1529, -11.824, -22.725, -26.701, -25...  \n",
       "1  [7.7133, 3.4957, -1.6378, -7.7151, -13.76, -18...  \n",
       "2  [-10.816, -11.143, -11.407, -11.518, -11.336, ...  \n",
       "3  [-86.666, -82.155, -76.289, -68.804, -61.092, ...  \n",
       "4  [-68.682, -67.147, -64.614, -60.604, -55.135, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ekg_df.head() # View dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7035c4",
   "metadata": {},
   "source": [
    "### 4. Save new ECG Dataframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_csv_path = r'datasets\\processed_ecg_data.csv' # Define a path that your want the newly created CSV to be stored. \n",
    "# final_ekg_df.to_csv(output_csv_path, index=False)        # converts the dataframe to a csv file located at the path defined above.\n",
    "\n",
    "# print(f\"DataFrame saved to: {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e4ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tf-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
