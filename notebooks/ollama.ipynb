{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d1b40a",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/Screenshot_ollama.jpeg\" alt=\"ollama_logo\" width=\"100\"/>\n",
    "   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "  <img src=\"images/Screenshot_ubuntu.png\" alt=\"ubuntu_logo\" width=\"100\"/>\n",
    "</p>\n",
    "\n",
    "# Goal of This Notebook:\n",
    "## Present the Ollama local model I used to interpret the Apple Watch outputs and the EKG_CNN prediction outputs and return a report paragraph\n",
    "\n",
    "* 1) Explain how to use the Ubuntu Command Line Interface (CLI) to interact with Ollama.\n",
    "\n",
    "* 2) Provide the code to create a custom Ollama model (ekgllm) using a Modelfile.\n",
    "\n",
    "* 3) Show how to run and interact with the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d2e90",
   "metadata": {},
   "source": [
    "## 1. Using the Ubuntu Command Line with Ollama\n",
    "Ollama is primarily a command-line tool. All the commands in this notebook are designed to be run from your Ubuntu terminal. You can execute shell commands directly in a Jupyter notebook cell by prefixing the command with an exclamation mark (!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df23d3",
   "metadata": {},
   "source": [
    "* https://ollama.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae2d68",
   "metadata": {},
   "source": [
    "**I would strongly recommend The Ollama Course:Basics**\n",
    "\n",
    "This is a youtube playlist by Matt Williams. It really helps to watch these videos\n",
    "\n",
    "https://www.youtube.com/watch?v=9KEUFe4KQAI&list=PLvsHpqLkpw0fIT-WbjY-xBRxTftjwiTLB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f4d38",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/Screenshot_ollama_download.png\" alt=\"ollama_download\" width=\"900\"/>\n",
    "</p>\n",
    "\n",
    "* (pic from) https://github.com/ollama/ollama?tab=readme-ov-file\n",
    "* (manual instructions link) https://github.com/ollama/ollama/blob/main/docs/linux.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead16406",
   "metadata": {},
   "source": [
    "## 2) Once Ollama is downloaded it is time to find the model to use.\n",
    " I used llama3.1:8b.  This was a larger model for my computer and I had to have to have plenty of memory available to run the script with this model. I tried smaller models but had a difficult time getting an accurate output. \n",
    " <p align=\"center\">\n",
    "  <img src=\"images/Screenshot_llama3.jpeg\" alt=\"llama_model\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "https://ollama.com/library/llama3.1:8b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebdc2c9",
   "metadata": {},
   "source": [
    "## 3) Create a Modelfile\n",
    "Once Ollama and the selected model are local, create a Modelfile. This github supplies the one I created.\n",
    "  \n",
    "\"ekgmodelfile\" [ekgmodelfile](https://github.com/bretttay24/ekg_applewatch/blob/main/ekgmodelfile)\n",
    "\n",
    "- Once the modelfile is open first add \"FROM llama3.1:8b \"  or \"From {exact model name from ollama}\"\n",
    "\n",
    "- Next provide a System prompt in the format of SYSTEM \"\"\" {system prompt} \"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519384c0",
   "metadata": {},
   "source": [
    "### Example of my file:\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/Screenshot_ekgmodelfile.png\" alt=\"ekgmodelfile\" width=\"700\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "[ekgmodelfile](https://github.com/bretttay24/ekg_applewatch/blob/main/ekgmodelfile)\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0c52c",
   "metadata": {},
   "source": [
    "## 4) Create custom local LLM\n",
    "- Use the ollama 'create' command to create the local LLM, combining the chosen imported LLM (mine was llama3.1:8b) and provide the system prompt file (mine was 'ekgmodelfile')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfef6b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
